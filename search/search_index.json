{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Welcome \u00b6 Currently, I am working as an optimisation engineer in AGCO Randers Innovation Center since the year 2018. I received my PhD from Aarhus University, the research group of Operations Management in 2015. My research focuses on the following topics: \ud83d\udccc Operations planning: mission planning, task scheduling and allocation \ud83d\udccc Field logistics: scheduling, area coverage planning, routing for machines and robots \ud83d\udccc Information engineering: Identifying relevant data sources for business needs, data processing, decision optimisation Route and path planning algorithms that I developed have been applied to the following AGCO products: 1\ufe0f\u20e3 Geo-Bird is an easy-to-use web application focusing on optimizing farming and reducing costs while at the same time improving the CO2 footprint, it is not just your tool for wayline creation but also analyses your field and optimizes the waylines for Controlled Traffic Farming(CTF) to reduce wheel traffic, time and soil compaction.I am responsible for the wayline planning and optimal wayline direction algorithms. (photos courtesy AGCO/Fuse) 2\ufe0f\u20e3 FendtONE Offboard complements the FendtONE onboard on the machine with practical, additional functions. For example, Fendt Task Doc, which records agronomy data/yield figures during field work (onboard), has been expanded with job planning and administration functions in Fendt Task Doc (offboard). My wayline planning algorithm is intergated in the system. (photos courtesy AGCO/Fendt) 3\ufe0f\u20e3 Fendt Xaver is a compact, electric-powered prototype that\u2019s designed to work autonomously in swarms in a field, with the aim of reducing soil compaction, energy consumption, and labour costs. My path and route planning algorithms is integated as a module of the entire robot system. (photos courtesy AGCO/Fendt)","title":"Welcome"},{"location":"#welcome","text":"Currently, I am working as an optimisation engineer in AGCO Randers Innovation Center since the year 2018. I received my PhD from Aarhus University, the research group of Operations Management in 2015. My research focuses on the following topics: \ud83d\udccc Operations planning: mission planning, task scheduling and allocation \ud83d\udccc Field logistics: scheduling, area coverage planning, routing for machines and robots \ud83d\udccc Information engineering: Identifying relevant data sources for business needs, data processing, decision optimisation Route and path planning algorithms that I developed have been applied to the following AGCO products: 1\ufe0f\u20e3 Geo-Bird is an easy-to-use web application focusing on optimizing farming and reducing costs while at the same time improving the CO2 footprint, it is not just your tool for wayline creation but also analyses your field and optimizes the waylines for Controlled Traffic Farming(CTF) to reduce wheel traffic, time and soil compaction.I am responsible for the wayline planning and optimal wayline direction algorithms. (photos courtesy AGCO/Fuse) 2\ufe0f\u20e3 FendtONE Offboard complements the FendtONE onboard on the machine with practical, additional functions. For example, Fendt Task Doc, which records agronomy data/yield figures during field work (onboard), has been expanded with job planning and administration functions in Fendt Task Doc (offboard). My wayline planning algorithm is intergated in the system. (photos courtesy AGCO/Fendt) 3\ufe0f\u20e3 Fendt Xaver is a compact, electric-powered prototype that\u2019s designed to work autonomously in swarms in a field, with the aim of reducing soil compaction, energy consumption, and labour costs. My path and route planning algorithms is integated as a module of the entire robot system. (photos courtesy AGCO/Fendt)","title":"Welcome"},{"location":"home/publications/","text":"Publications \u00b6 \ud83d\udcd7 : Published \ud83d\udcd5 : Under review Journal papers \u00b6 \ud83d\udcd7 Chen, Y., Li, G., Zhang, X., Jia, J., Zhou, K. , & Wu, C. (2022). Identifying field and road modes of agricultural Machinery based on GNSS Recordings: A graph convolutional neural network approach. Computers and Electronics in Agriculture, 198, 107082. \ud83d\udcd7 Liang, Y., Zhou, K. , & Wu, C. (2022). Environment scenario identification based on GNSS recordings for agricultural tractors. Computers and Electronics in Agriculture, 195, 106829.\ud83d\udea9[co-corresponding author] \ud83d\udcd7 Vahdanjoo, M., Zhou, K. , & S\u00f8rensen, C. A. G. (2020). Route planning for agricultural machines with multiple depots: manure application case study. Agronomy, 10(10), 1608.\ud83d\udea9[co-first author] \ud83d\udcd7 Nilsson, R. S., & Zhou, K . (2020). Method and bench-marking framework for coverage path planning in arable farming. Biosystems Engineering, 198, 248-265. \ud83d\udcd7 Nilsson, R. S., & Zhou, K . (2020). Decision support tool for operational planning of field operations. Agronomy, 10(2), 229. \ud83d\udcd7 Zhou, K. , Jensen, A. L., Bochtis, D., N\u00f8rremark, M., Kateris, D., & S\u00f8rensen, C. G. (2020). Metric map generation for autonomous field operations. Agronomy, 10(1), 83. \ud83d\udcd7 Zhou, K. , Bochtis, D., Jensen, A. L., Kateris, D., & S\u00f8rensen, C. G. (2020). Introduction of a new index of field operations efficiency. Applied Sciences, 10(1), 329. \ud83d\udcd7 Rodias, E., Berruto, R., Busato, P., Bochtis, D., S\u00f8rensen, C. G., & Zhou, K (2017). Energy savings from optimised in-field route planning for agricultural machinery. Sustainability, 9(11), 1956. \ud83d\udcd7 Zhou, K. , Jensen, A. L., Bochtis, D. D., & S\u00f8rensen, C. G. (2015). Quantifying the benefits of alternative fieldwork patterns in a potato cultivation system. Computers and Electronics in Agriculture, 119, 228-240. \ud83d\udcd7 Zhou, K. , Jensen, A. L., Bochtis, D. D., & S\u00f8rensen, C. G. (2015). Simulation model for the sequential in-field machinery operations in a potato production system. Computers and Electronics in Agriculture, 116, 173-186. \ud83d\udcd7 Bochtis, D., Griepentrog, H. W., Vougioukas, S., Busato, P., Berruto, R., & Zhou, K . (2015). Route planning for orchard operations. Computers and electronics in agriculture, 113, 51-60. \ud83d\udcd7 Zhou, K. , Jensen, A. L., Bochtis, D., & S\u00f8rensen, C. G. (2015). Performance of machinery in potato production in one growing season. Spanish journal of agricultural research, 13(4), 6. \ud83d\udcd7 Zhou, K. , Jensen, A. L., S\u00f8rensen, C. G., Busato, P., & Bothtis, D. D. (2014). Agricultural operations planning in fields with multiple obstacle areas. Computers and electronics in agriculture, 109, 12-22. Conference proceedings \u00b6 \ud83d\udcd7 Zhou, K. , Bochtis, D. (2015, September). Route Planning For Capacitated Agricultural Machines Based On Ant Colony Algorithms. In HAICTA (pp. 163-173). \ud83d\udcd7 Zhou, K. , Zhou, K., Bothtis, D. D., S\u00f8rensen, C. G., (2016). An object-oriented simulation tool for grain harvesting. CIGR-AgEng Conference, 26-29 June 2016, Aarhus \ud83d\udcd7 Jensen, A., la Riviere, I. J., de Bruin, S., Zhou, K. , J\u00f8rgensen, M. S., Pedersen, H., S\u00f8rensen, C. G. (2018). An online DSS for optimisation of traffic in fields with controlled traffic farming (CTF). In CIGR 2018: XIX. World Congress of CIGR (Commission Internationale du G\u00e9nie Rural) Program & Abstracts' Book: Sustainable Life for Children (pp. 154-154). CIGR. \ud83d\udcd7 Zhou, K. , Jensen, A. L., Bochtis, D., S\u00f8rensen, C. G. A Web\u2013based Tool for Comparing Field Area Coverage Practices. CIOSTA XXXV Conference: CIGR V Conference, Billund, Denmark; 07/2013. \ud83d\udcd7 Gunnarsson, E. Rodias, J. Kusk, Zhou, K. . M. A. F. Jensen, D. D. Bochtis. Biomass crop allocation problem. International Commission of Agricultural and Biological Engineers, Section V. CIOSTA XXXV Conference \u201cFrom Effective to Intelligent Agriculture and Forestry\u201d, Billund, Denmark, 3-5 July 2013. Patents \u00b6 \ud83d\udcd5 Zhou, K. , (2019). System And Method For Windrow Path Planning. U. S. Patent Application No. 202017135996. Washington, DC: U. S. Patent and Trademark Office. \ud83d\udcd5 Zhou, K. , System And Method For Windrow Path Planning. U. S. Patent Application No. 202017135990. Washington, DC: U. S. Patent and Trademark Office. \ud83d\udcd5 Zhou, K. , Nilsson, R. S., Kenneth, G. L. (2022). Operational path planning. G. B. Patent Application No. 202201115. Newport, South East Wales: Intellectual Property Office. \ud83d\udcd5 Zhou, K. , Nilsson, R. S., Kenneth, G. L. (2022). Operational path planning. G. B. Patent Application No. 202202445. Newport, South East Wales: Intellectual Property Office. \ud83d\udcd5 Zhou, K. , Nilsson, R. S., Kenneth, G. L. (2022). Wayline Generation for farming machine guidance. Patent Application No. Unkown yet. Washington, DC: U. S. Patent and Trademark Office.","title":"Publications"},{"location":"home/publications/#publications","text":"\ud83d\udcd7 : Published \ud83d\udcd5 : Under review","title":"Publications"},{"location":"home/publications/#journal-papers","text":"\ud83d\udcd7 Chen, Y., Li, G., Zhang, X., Jia, J., Zhou, K. , & Wu, C. (2022). Identifying field and road modes of agricultural Machinery based on GNSS Recordings: A graph convolutional neural network approach. Computers and Electronics in Agriculture, 198, 107082. \ud83d\udcd7 Liang, Y., Zhou, K. , & Wu, C. (2022). Environment scenario identification based on GNSS recordings for agricultural tractors. Computers and Electronics in Agriculture, 195, 106829.\ud83d\udea9[co-corresponding author] \ud83d\udcd7 Vahdanjoo, M., Zhou, K. , & S\u00f8rensen, C. A. G. (2020). Route planning for agricultural machines with multiple depots: manure application case study. Agronomy, 10(10), 1608.\ud83d\udea9[co-first author] \ud83d\udcd7 Nilsson, R. S., & Zhou, K . (2020). Method and bench-marking framework for coverage path planning in arable farming. Biosystems Engineering, 198, 248-265. \ud83d\udcd7 Nilsson, R. S., & Zhou, K . (2020). Decision support tool for operational planning of field operations. Agronomy, 10(2), 229. \ud83d\udcd7 Zhou, K. , Jensen, A. L., Bochtis, D., N\u00f8rremark, M., Kateris, D., & S\u00f8rensen, C. G. (2020). Metric map generation for autonomous field operations. Agronomy, 10(1), 83. \ud83d\udcd7 Zhou, K. , Bochtis, D., Jensen, A. L., Kateris, D., & S\u00f8rensen, C. G. (2020). Introduction of a new index of field operations efficiency. Applied Sciences, 10(1), 329. \ud83d\udcd7 Rodias, E., Berruto, R., Busato, P., Bochtis, D., S\u00f8rensen, C. G., & Zhou, K (2017). Energy savings from optimised in-field route planning for agricultural machinery. Sustainability, 9(11), 1956. \ud83d\udcd7 Zhou, K. , Jensen, A. L., Bochtis, D. D., & S\u00f8rensen, C. G. (2015). Quantifying the benefits of alternative fieldwork patterns in a potato cultivation system. Computers and Electronics in Agriculture, 119, 228-240. \ud83d\udcd7 Zhou, K. , Jensen, A. L., Bochtis, D. D., & S\u00f8rensen, C. G. (2015). Simulation model for the sequential in-field machinery operations in a potato production system. Computers and Electronics in Agriculture, 116, 173-186. \ud83d\udcd7 Bochtis, D., Griepentrog, H. W., Vougioukas, S., Busato, P., Berruto, R., & Zhou, K . (2015). Route planning for orchard operations. Computers and electronics in agriculture, 113, 51-60. \ud83d\udcd7 Zhou, K. , Jensen, A. L., Bochtis, D., & S\u00f8rensen, C. G. (2015). Performance of machinery in potato production in one growing season. Spanish journal of agricultural research, 13(4), 6. \ud83d\udcd7 Zhou, K. , Jensen, A. L., S\u00f8rensen, C. G., Busato, P., & Bothtis, D. D. (2014). Agricultural operations planning in fields with multiple obstacle areas. Computers and electronics in agriculture, 109, 12-22.","title":"Journal papers"},{"location":"home/publications/#conference-proceedings","text":"\ud83d\udcd7 Zhou, K. , Bochtis, D. (2015, September). Route Planning For Capacitated Agricultural Machines Based On Ant Colony Algorithms. In HAICTA (pp. 163-173). \ud83d\udcd7 Zhou, K. , Zhou, K., Bothtis, D. D., S\u00f8rensen, C. G., (2016). An object-oriented simulation tool for grain harvesting. CIGR-AgEng Conference, 26-29 June 2016, Aarhus \ud83d\udcd7 Jensen, A., la Riviere, I. J., de Bruin, S., Zhou, K. , J\u00f8rgensen, M. S., Pedersen, H., S\u00f8rensen, C. G. (2018). An online DSS for optimisation of traffic in fields with controlled traffic farming (CTF). In CIGR 2018: XIX. World Congress of CIGR (Commission Internationale du G\u00e9nie Rural) Program & Abstracts' Book: Sustainable Life for Children (pp. 154-154). CIGR. \ud83d\udcd7 Zhou, K. , Jensen, A. L., Bochtis, D., S\u00f8rensen, C. G. A Web\u2013based Tool for Comparing Field Area Coverage Practices. CIOSTA XXXV Conference: CIGR V Conference, Billund, Denmark; 07/2013. \ud83d\udcd7 Gunnarsson, E. Rodias, J. Kusk, Zhou, K. . M. A. F. Jensen, D. D. Bochtis. Biomass crop allocation problem. International Commission of Agricultural and Biological Engineers, Section V. CIOSTA XXXV Conference \u201cFrom Effective to Intelligent Agriculture and Forestry\u201d, Billund, Denmark, 3-5 July 2013.","title":"Conference proceedings"},{"location":"home/publications/#patents","text":"\ud83d\udcd5 Zhou, K. , (2019). System And Method For Windrow Path Planning. U. S. Patent Application No. 202017135996. Washington, DC: U. S. Patent and Trademark Office. \ud83d\udcd5 Zhou, K. , System And Method For Windrow Path Planning. U. S. Patent Application No. 202017135990. Washington, DC: U. S. Patent and Trademark Office. \ud83d\udcd5 Zhou, K. , Nilsson, R. S., Kenneth, G. L. (2022). Operational path planning. G. B. Patent Application No. 202201115. Newport, South East Wales: Intellectual Property Office. \ud83d\udcd5 Zhou, K. , Nilsson, R. S., Kenneth, G. L. (2022). Operational path planning. G. B. Patent Application No. 202202445. Newport, South East Wales: Intellectual Property Office. \ud83d\udcd5 Zhou, K. , Nilsson, R. S., Kenneth, G. L. (2022). Wayline Generation for farming machine guidance. Patent Application No. Unkown yet. Washington, DC: U. S. Patent and Trademark Office.","title":"Patents"},{"location":"home/data-handling/Pandas-split-columns/","text":"Split a text column into two columns in Pandas DataFrame \u00b6 Using Series.str.split() functions \u00b6 df = pd . DataFrame ({ 'name' : [ 'John Larter' , 'Robert Junior' , 'Jonny Depp' ], 'age' :[ 32 , 34 , 36 ]}) print ( \"Given Dataframe is : \\n \" , df ) # bydefault splitting is done on the basis of single space. print ( \" \\n Splitting 'Name' column into two different columns : \\n \" , df . name . str . split ( expand = True )) The output is Split Name column into \u201cFirst\u201d and \u201cLast\u201d column respectively and add it to the existing Dataframe. # create a new data frame df = pd . DataFrame ({ 'name' : [ 'John_Larter' , 'Robert_Junior' , 'Jonny_Depp' ], 'age' :[ 32 , 34 , 36 ]}) print ( \"Given Dataframe is : \\n \" , df ) # Adding two new columns to the existing dataframe. # bydefault splitting is done on the basis of '_'. df [[ 'First' , 'Last' ]] = df . name . str . split ( '-' , expand = True ) print ( \" \\n After adding two new columns : \\n \" , df ) The output is","title":"Split a text column into two columns in Pandas DataFrame"},{"location":"home/data-handling/Pandas-split-columns/#split-a-text-column-into-two-columns-in-pandas-dataframe","text":"","title":"Split a text column into two columns in Pandas DataFrame"},{"location":"home/data-handling/Pandas-split-columns/#using-seriesstrsplit-functions","text":"df = pd . DataFrame ({ 'name' : [ 'John Larter' , 'Robert Junior' , 'Jonny Depp' ], 'age' :[ 32 , 34 , 36 ]}) print ( \"Given Dataframe is : \\n \" , df ) # bydefault splitting is done on the basis of single space. print ( \" \\n Splitting 'Name' column into two different columns : \\n \" , df . name . str . split ( expand = True )) The output is Split Name column into \u201cFirst\u201d and \u201cLast\u201d column respectively and add it to the existing Dataframe. # create a new data frame df = pd . DataFrame ({ 'name' : [ 'John_Larter' , 'Robert_Junior' , 'Jonny_Depp' ], 'age' :[ 32 , 34 , 36 ]}) print ( \"Given Dataframe is : \\n \" , df ) # Adding two new columns to the existing dataframe. # bydefault splitting is done on the basis of '_'. df [[ 'First' , 'Last' ]] = df . name . str . split ( '-' , expand = True ) print ( \" \\n After adding two new columns : \\n \" , df ) The output is","title":"Using Series.str.split() functions"},{"location":"home/data-handling/Pandas%3Arename-columns/","text":"Rename columns in Pandas \u00b6 You can use one of the following three methods to rename columns in a pandas DataFrame: Method 1: Rename Specific Columns df . rename ( columns = { 'old_col1' : 'new_col1' , 'old_col2' : 'new_col2' }, inplace = True ) Code example: import pandas as pd #define DataFrame df = pd . DataFrame ({ 'team' :[ 'A' , 'A' , 'A' , 'A' , 'B' , 'B' , 'B' , 'B' ], 'points' : [ 25 , 12 , 15 , 14 , 19 , 23 , 25 , 29 ], 'assists' : [ 5 , 7 , 7 , 9 , 12 , 9 , 9 , 4 ], 'rebounds' : [ 11 , 8 , 10 , 6 , 6 , 5 , 9 , 12 ]}) #list column names list ( df ) [ 'team' , 'points' , 'assists' , 'rebounds' ] #rename specific column names df . rename ( columns = { 'team' : 'team_name' , 'points' : 'points_scored' }, inplace = True ) #view updated list of column names list ( df ) [ 'team_name' , 'points_scored' , 'assists' , 'rebounds' ] Method 2: Rename All Columns df . columns = [ 'new_col1' , 'new_col2' , 'new_col3' , 'new_col4' ] Code example: import pandas as pd #define DataFrame df = pd . DataFrame ({ 'team' :[ 'A' , 'A' , 'A' , 'A' , 'B' , 'B' , 'B' , 'B' ], 'points' : [ 25 , 12 , 15 , 14 , 19 , 23 , 25 , 29 ], 'assists' : [ 5 , 7 , 7 , 9 , 12 , 9 , 9 , 4 ], 'rebounds' : [ 11 , 8 , 10 , 6 , 6 , 5 , 9 , 12 ]}) #list column names list ( df ) [ 'team' , 'points' , 'assists' , 'rebounds' ] #rename all column names df . columns = [ '_team' , '_points' , '_assists' , '_rebounds' ] #view updated list of column names list ( df ) [ '_team' , '_points' , '_assists' , '_rebounds' ] Method 3: Replace Specific Characters in Columns df . columns = df . columns . str . replace ( 'old_char' , 'new_char' ) Code example: import pandas as pd #define DataFrame df = pd . DataFrame ({ '$team' :[ 'A' , 'A' , 'A' , 'A' , 'B' , 'B' , 'B' , 'B' ], '$points' : [ 25 , 12 , 15 , 14 , 19 , 23 , 25 , 29 ], '$assists' : [ 5 , 7 , 7 , 9 , 12 , 9 , 9 , 4 ], '$rebounds' : [ 11 , 8 , 10 , 6 , 6 , 5 , 9 , 12 ]}) #list column names list ( df ) [ 'team' , 'points' , 'assists' , 'rebounds' ] #rename $ with blank in every column name df . columns = df . columns . str . replace ( '$' , '' ) #view updated list of column names list ( df ) [ 'team' , 'points' , 'assists' , 'rebounds' ] Reference and related articles How to Rename Columns in Pandas","title":"Rename columns in Pandas"},{"location":"home/data-handling/Pandas%3Arename-columns/#rename-columns-in-pandas","text":"You can use one of the following three methods to rename columns in a pandas DataFrame: Method 1: Rename Specific Columns df . rename ( columns = { 'old_col1' : 'new_col1' , 'old_col2' : 'new_col2' }, inplace = True ) Code example: import pandas as pd #define DataFrame df = pd . DataFrame ({ 'team' :[ 'A' , 'A' , 'A' , 'A' , 'B' , 'B' , 'B' , 'B' ], 'points' : [ 25 , 12 , 15 , 14 , 19 , 23 , 25 , 29 ], 'assists' : [ 5 , 7 , 7 , 9 , 12 , 9 , 9 , 4 ], 'rebounds' : [ 11 , 8 , 10 , 6 , 6 , 5 , 9 , 12 ]}) #list column names list ( df ) [ 'team' , 'points' , 'assists' , 'rebounds' ] #rename specific column names df . rename ( columns = { 'team' : 'team_name' , 'points' : 'points_scored' }, inplace = True ) #view updated list of column names list ( df ) [ 'team_name' , 'points_scored' , 'assists' , 'rebounds' ] Method 2: Rename All Columns df . columns = [ 'new_col1' , 'new_col2' , 'new_col3' , 'new_col4' ] Code example: import pandas as pd #define DataFrame df = pd . DataFrame ({ 'team' :[ 'A' , 'A' , 'A' , 'A' , 'B' , 'B' , 'B' , 'B' ], 'points' : [ 25 , 12 , 15 , 14 , 19 , 23 , 25 , 29 ], 'assists' : [ 5 , 7 , 7 , 9 , 12 , 9 , 9 , 4 ], 'rebounds' : [ 11 , 8 , 10 , 6 , 6 , 5 , 9 , 12 ]}) #list column names list ( df ) [ 'team' , 'points' , 'assists' , 'rebounds' ] #rename all column names df . columns = [ '_team' , '_points' , '_assists' , '_rebounds' ] #view updated list of column names list ( df ) [ '_team' , '_points' , '_assists' , '_rebounds' ] Method 3: Replace Specific Characters in Columns df . columns = df . columns . str . replace ( 'old_char' , 'new_char' ) Code example: import pandas as pd #define DataFrame df = pd . DataFrame ({ '$team' :[ 'A' , 'A' , 'A' , 'A' , 'B' , 'B' , 'B' , 'B' ], '$points' : [ 25 , 12 , 15 , 14 , 19 , 23 , 25 , 29 ], '$assists' : [ 5 , 7 , 7 , 9 , 12 , 9 , 9 , 4 ], '$rebounds' : [ 11 , 8 , 10 , 6 , 6 , 5 , 9 , 12 ]}) #list column names list ( df ) [ 'team' , 'points' , 'assists' , 'rebounds' ] #rename $ with blank in every column name df . columns = df . columns . str . replace ( '$' , '' ) #view updated list of column names list ( df ) [ 'team' , 'points' , 'assists' , 'rebounds' ] Reference and related articles How to Rename Columns in Pandas","title":"Rename columns in Pandas"},{"location":"home/machine-learning/feature-scaling/","text":"Feature scaling \u00b6 Feature scaling in machine learning is one of the most critical steps during the pre-processing of data before creating a machine learning model, which is used to normalize the range of independent variables or features of data. Methods for Scaling \u00b6 Min-max normalization \u00b6 Also known as min-max scaling or min-max normalization , rescaling is the simplest method and consists in rescaling the range of features to scale the range in [0, 1] or [\u22121, 1]. Selecting the target range depends on the nature of the data. The general formula for a min-max of [0, 1] is given as: \\[ x'={\\frac{x-{\\text{min}}(x)}{{\\text{max}}(x)-{\\text{min}}(x)}} \\] where \\(x\\) is an original value, \\(x'\\) is the normalized value. For example, suppose that we have the students' weight data, and the students' weights span [160 pounds, 200 pounds]. To rescale this data, we first subtract 160 from each student's weight and divide the result by the difference between the maximum and minimum weights, 40. To rescale a range between an arbitrary set of values \\([a, b]\\) , the formula becomes: \\[ {\\displaystyle x'=a+{\\frac {(x-{\\text{min}}(x))(b-a)}{{\\text{max}}(x)-{\\text{min}}(x)}}} \\] where \\(a\\) , \\(b\\) are the min-max values. Mean normalization \u00b6 \\[ x' = \\frac{x- \\text{average}(x)}{\\text{max}(x)-\\text{min}(x)} \\] where \\(x\\) is an original value, \\(x'\\) is the normalized value. Standardization (Z-score Normalization) \u00b6 Feature standardization makes the values of each feature in the data have zero-mean . (when subtracting the mean in the numerator) and unit-variance . This method is widely used for normalization in many machine learning algorithms (e.g., support vector machines, logistic regression, and artificial neural networks). The general method of calculation is to determine the distribution mean and standard deviation for each feature. Next we subtract the mean from each feature. Then we divide the values (mean is already subtracted) of each feature by its standard deviation. \\[ x' = \\frac{x- \\bar{x}}{\\sigma} \\] where \\(x\\) is the original feature vector, \\({\\bar {x}}={\\text{average}}(x)\\) is the mean of that feature vector, and \\(\\sigma\\) is its standard deviation. When to use Normalization or Standardizatio \u00b6 If you have ever built a machine learning pipeline, you must have always faced this question of whether to Normalize or to Standardize. While there is no obvious answer to this question, it really depends on the application, there are still a few generalizations that can be drawn. Normalization is good to use when the distribution of data does not follow a Gaussian distribution . It can be useful in algorithms that do not assume any distribution of the data like K-Nearest Neighbors. In Neural Networks algorithm that require data on a 0\u20131 scale, normalization is an essential pre-processing step. Another popular example of data normalization is image processing, where pixel intensities have to be normalized to fit within a certain range (i.e., 0 to 255 for the RGB color range). Standardization can be helpful in cases where the data follows a Gaussian distribution . Though this does not have to be necessarily true. Since standardization does not have a bounding range, so, even if there are outliers in the data, they will not be affected by standardization. In clustering analyses, standardization comes in handy to compare similarities between features based on certain distance measures. Another prominent example is the Principal Component Analysis, where we usually prefer standardization over Min-Max scaling since we are interested in the components that maximize the variance. There are some points which can be considered while deciding whether we need Standardization or Normalization Standardization may be used when data represent Gaussian Distribution, while Normalization is great with Non-Gaussian Distribution Impact of Outliers is very high in Normalization To conclude, you can always start by fitting your model to raw, normalized, and standardized data and compare the performance for the best results. Reference and related articles All about Feature Scaling When to perform a Feature Scaling? Wiki-Feature scaling","title":"Feature scaling"},{"location":"home/machine-learning/feature-scaling/#feature-scaling","text":"Feature scaling in machine learning is one of the most critical steps during the pre-processing of data before creating a machine learning model, which is used to normalize the range of independent variables or features of data.","title":"Feature scaling"},{"location":"home/machine-learning/feature-scaling/#methods-for-scaling","text":"","title":"Methods for Scaling"},{"location":"home/machine-learning/feature-scaling/#min-max-normalization","text":"Also known as min-max scaling or min-max normalization , rescaling is the simplest method and consists in rescaling the range of features to scale the range in [0, 1] or [\u22121, 1]. Selecting the target range depends on the nature of the data. The general formula for a min-max of [0, 1] is given as: \\[ x'={\\frac{x-{\\text{min}}(x)}{{\\text{max}}(x)-{\\text{min}}(x)}} \\] where \\(x\\) is an original value, \\(x'\\) is the normalized value. For example, suppose that we have the students' weight data, and the students' weights span [160 pounds, 200 pounds]. To rescale this data, we first subtract 160 from each student's weight and divide the result by the difference between the maximum and minimum weights, 40. To rescale a range between an arbitrary set of values \\([a, b]\\) , the formula becomes: \\[ {\\displaystyle x'=a+{\\frac {(x-{\\text{min}}(x))(b-a)}{{\\text{max}}(x)-{\\text{min}}(x)}}} \\] where \\(a\\) , \\(b\\) are the min-max values.","title":"Min-max normalization"},{"location":"home/machine-learning/feature-scaling/#mean-normalization","text":"\\[ x' = \\frac{x- \\text{average}(x)}{\\text{max}(x)-\\text{min}(x)} \\] where \\(x\\) is an original value, \\(x'\\) is the normalized value.","title":"Mean normalization"},{"location":"home/machine-learning/feature-scaling/#standardization-z-score-normalization","text":"Feature standardization makes the values of each feature in the data have zero-mean . (when subtracting the mean in the numerator) and unit-variance . This method is widely used for normalization in many machine learning algorithms (e.g., support vector machines, logistic regression, and artificial neural networks). The general method of calculation is to determine the distribution mean and standard deviation for each feature. Next we subtract the mean from each feature. Then we divide the values (mean is already subtracted) of each feature by its standard deviation. \\[ x' = \\frac{x- \\bar{x}}{\\sigma} \\] where \\(x\\) is the original feature vector, \\({\\bar {x}}={\\text{average}}(x)\\) is the mean of that feature vector, and \\(\\sigma\\) is its standard deviation.","title":"Standardization (Z-score Normalization)"},{"location":"home/machine-learning/feature-scaling/#when-to-use-normalization-or-standardizatio","text":"If you have ever built a machine learning pipeline, you must have always faced this question of whether to Normalize or to Standardize. While there is no obvious answer to this question, it really depends on the application, there are still a few generalizations that can be drawn. Normalization is good to use when the distribution of data does not follow a Gaussian distribution . It can be useful in algorithms that do not assume any distribution of the data like K-Nearest Neighbors. In Neural Networks algorithm that require data on a 0\u20131 scale, normalization is an essential pre-processing step. Another popular example of data normalization is image processing, where pixel intensities have to be normalized to fit within a certain range (i.e., 0 to 255 for the RGB color range). Standardization can be helpful in cases where the data follows a Gaussian distribution . Though this does not have to be necessarily true. Since standardization does not have a bounding range, so, even if there are outliers in the data, they will not be affected by standardization. In clustering analyses, standardization comes in handy to compare similarities between features based on certain distance measures. Another prominent example is the Principal Component Analysis, where we usually prefer standardization over Min-Max scaling since we are interested in the components that maximize the variance. There are some points which can be considered while deciding whether we need Standardization or Normalization Standardization may be used when data represent Gaussian Distribution, while Normalization is great with Non-Gaussian Distribution Impact of Outliers is very high in Normalization To conclude, you can always start by fitting your model to raw, normalized, and standardized data and compare the performance for the best results. Reference and related articles All about Feature Scaling When to perform a Feature Scaling? Wiki-Feature scaling","title":"When to use Normalization or Standardizatio"},{"location":"home/statistics/identify-outliers/","text":"Ways to identify outliers \u00b6 Outliers are extreme values that differ from most other data points in a dataset. They can have a big impact on your statistical analyses and skew the results of any hypothesis tests. True outliers should always be retained in your dataset because these just represent natural variations in your sample. Sorting method \u00b6 You can sort quantitative variables from low to high in ascending order and find out extremely low or extremely high values. Flag any extreme values that you find. This is a simple way to check whether you need to investigate certain data points before using more sophisticated methods. Data visualizations \u00b6 Two of the most common graphical ways of detecting outliers are the boxplot and the scatterplot. A boxplot is my favorite way. You can see here that the blue circles are outliers, where the open circles representing mild outliers, and closed circles representing extreme outliers: Statistical outlier detection \u00b6 Statistical outlier detection involves applying statistical tests or procedures to identify extreme values. You can convert extreme data points into z scores that tell you how many standard deviations away they are from the mean. If a value has a high enough or low enough z score, it can be considered an outlier. As a rule of thumb, values with a z score greater than 3 or less than \u20133 are often determined to be outliers 1 . Using the interquartile range(IQR) \u00b6 We can use the IQR method of identifying outliers to set up a \u201cfence\u201d outside of Q1 and Q3. Any values that fall outside of this fence are considered outliers. Interquartile range method: * Sort your data from low to high * Identify the first quartile (Q1), the median, and the third quartile (Q3). * Calculate your IQR = Q3 \u2013 Q1 * Calculate your upper fence = Q3 + (1.5 * IQR) * Calculate your lower fence = Q1 \u2013 (1.5 * IQR) * Use your fences to highlight any outliers, all values that fall outside your fences. Your outliers are any values greater than your upper fence or less than your lower fence.","title":"Ways to identify outliers"},{"location":"home/statistics/identify-outliers/#ways-to-identify-outliers","text":"Outliers are extreme values that differ from most other data points in a dataset. They can have a big impact on your statistical analyses and skew the results of any hypothesis tests. True outliers should always be retained in your dataset because these just represent natural variations in your sample.","title":"Ways to identify outliers"},{"location":"home/statistics/identify-outliers/#sorting-method","text":"You can sort quantitative variables from low to high in ascending order and find out extremely low or extremely high values. Flag any extreme values that you find. This is a simple way to check whether you need to investigate certain data points before using more sophisticated methods.","title":"Sorting method"},{"location":"home/statistics/identify-outliers/#data-visualizations","text":"Two of the most common graphical ways of detecting outliers are the boxplot and the scatterplot. A boxplot is my favorite way. You can see here that the blue circles are outliers, where the open circles representing mild outliers, and closed circles representing extreme outliers:","title":"Data visualizations"},{"location":"home/statistics/identify-outliers/#statistical-outlier-detection","text":"Statistical outlier detection involves applying statistical tests or procedures to identify extreme values. You can convert extreme data points into z scores that tell you how many standard deviations away they are from the mean. If a value has a high enough or low enough z score, it can be considered an outlier. As a rule of thumb, values with a z score greater than 3 or less than \u20133 are often determined to be outliers 1 .","title":"Statistical outlier detection"},{"location":"home/statistics/identify-outliers/#using-the-interquartile-rangeiqr","text":"We can use the IQR method of identifying outliers to set up a \u201cfence\u201d outside of Q1 and Q3. Any values that fall outside of this fence are considered outliers. Interquartile range method: * Sort your data from low to high * Identify the first quartile (Q1), the median, and the third quartile (Q3). * Calculate your IQR = Q3 \u2013 Q1 * Calculate your upper fence = Q3 + (1.5 * IQR) * Calculate your lower fence = Q1 \u2013 (1.5 * IQR) * Use your fences to highlight any outliers, all values that fall outside your fences. Your outliers are any values greater than your upper fence or less than your lower fence.","title":"Using the interquartile range(IQR)"}]}